{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a55fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "# Define parameters\n",
    "batch_size = 32\n",
    "sequence_length = 100  # Number of time steps\n",
    "vector_size = 16       # Features at each time step\n",
    "embedding_dim = vector_size  # Embedding size matches vector_size\n",
    "\n",
    "# Sample input tensor\n",
    "inputs = torch.rand(batch_size, sequence_length, vector_size)  # [batch, seq_len, vector_size]\n",
    "\n",
    "# Positional embeddings\n",
    "positional_embeddings = nn.Embedding(sequence_length, embedding_dim)\n",
    "positions = torch.arange(sequence_length).expand(batch_size, -1)  # [batch, seq_len]\n",
    "pos_embeds = positional_embeddings(positions)  # [batch, seq_len, embedding_dim]\n",
    "\n",
    "# Add positional embeddings to inputs\n",
    "inputs_with_pos = inputs + pos_embeds\n",
    "\n",
    "# Generate time-series specific embeddings\n",
    "# Time-of-day and day-of-week features\n",
    "time_of_day = torch.randint(0, 24, (batch_size, sequence_length))  # Hour of the day\n",
    "day_of_week = torch.randint(0, 7, (batch_size, sequence_length))  # Day of the week\n",
    "\n",
    "# Time embeddings for time-of-day and day-of-week\n",
    "time_of_day_embedding = nn.Embedding(24, embedding_dim)\n",
    "day_of_week_embedding = nn.Embedding(7, embedding_dim)\n",
    "\n",
    "# Encode time features\n",
    "time_of_day_embeds = time_of_day_embedding(time_of_day)  # [batch, seq_len, embedding_dim]\n",
    "day_of_week_embeds = day_of_week_embedding(day_of_week)  # [batch, seq_len, embedding_dim]\n",
    "\n",
    "# Combine time-of-day and day-of-week embeddings\n",
    "time_series_embedding = time_of_day_embeds + day_of_week_embeds  # [batch, seq_len, embedding_dim]\n",
    "\n",
    "# Add time differences as an additional feature\n",
    "time_differences = torch.rand(batch_size, sequence_length)  # Simulate time differences\n",
    "time_diff_embedding_layer = nn.Linear(1, embedding_dim)\n",
    "time_diff_embeds = time_diff_embedding_layer(time_differences.unsqueeze(-1))  # [batch, seq_len, embedding_dim]\n",
    "\n",
    "# Use frequency-domain features (e.g., Fourier transforms) to encode periodicity\n",
    "frequency_features = torch.fft.rfft(inputs, dim=1).abs()  # Magnitude of Fourier transform\n",
    "freq_embedding_layer = nn.Linear(frequency_features.shape[-1], embedding_dim)\n",
    "freq_embeds = freq_embedding_layer(frequency_features)  # [batch, seq_len, embedding_dim]\n",
    "\n",
    "# Introduce trainable parameters for embedding additional temporal events (e.g., holidays, anomalies)\n",
    "# Assume binary indicators for holidays and anomalies\n",
    "holiday_indicators = torch.randint(0, 2, (batch_size, sequence_length))  # Binary indicator\n",
    "anomaly_indicators = torch.randint(0, 2, (batch_size, sequence_length))  # Binary indicator\n",
    "\n",
    "holiday_embedding = nn.Embedding(2, embedding_dim)\n",
    "anomaly_embedding = nn.Embedding(2, embedding_dim)\n",
    "\n",
    "holiday_embeds = holiday_embedding(holiday_indicators)  # [batch, seq_len, embedding_dim]\n",
    "anomaly_embeds = anomaly_embedding(anomaly_indicators)  # [batch, seq_len, embedding_dim]\n",
    "\n",
    "# Convolutional layer to extract local patterns\n",
    "class ConvFeatureExtractor(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, kernel_size=3):\n",
    "        super(ConvFeatureExtractor, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_dim, output_dim, kernel_size, padding=kernel_size//2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(output_dim, output_dim, kernel_size, padding=kernel_size//2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Reshape input for Conv1d: [batch, vector_size, sequence_length]\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.conv2(x)\n",
    "        # Reshape back to [batch, sequence_length, output_dim]\n",
    "        return x.permute(0, 2, 1)\n",
    "\n",
    "# Instantiate convolutional feature extractor\n",
    "conv_extractor = ConvFeatureExtractor(input_dim=vector_size, output_dim=embedding_dim, kernel_size=3)\n",
    "\n",
    "# Apply convolutional feature extraction\n",
    "conv_features = conv_extractor(inputs)  # [batch, seq_len, embedding_dim]\n",
    "\n",
    "# Combine all embeddings\n",
    "final_inputs = (\n",
    "    conv_features\n",
    "    + inputs_with_pos\n",
    "    + time_series_embedding\n",
    "    + time_diff_embeds\n",
    "    + freq_embeds\n",
    "    + holiday_embeds\n",
    "    + anomaly_embeds\n",
    ")\n",
    "\n",
    "print(\"Final input tensor shape after convolutions and embeddings:\", final_inputs.shape)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}